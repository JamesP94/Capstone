{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in CSV file\n",
    "survey_response = pd.read_csv('survey_response.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of words to ignore\n",
    "unwanted_words = {'plane', 'sun', 'country', 'fly', 'flying'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    # Typecast to string if text is not already a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    # Load English stop words from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Convert text to lowercase for case folding\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation using a regular expression\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text by splitting on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "     # Remove stop words and unwanted words from tokens\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words and token not in unwanted_words]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_lda_analysis(file_path, num_topics=5, passes=20, random_state=42):\n",
    "    # Read and preprocess text\n",
    "    texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for comment in file:\n",
    "            processed_comment = process_text(comment)\n",
    "            if processed_comment:  # Check if comment is not empty after preprocessing\n",
    "                texts.append(processed_comment)\n",
    "    \n",
    "    # Create a dictionary and corpus\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # LDA model\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "\n",
    "    return lda_model, corpus, dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File paths\n",
    "high_score_file_path = 'high_score_comments.txt'\n",
    "low_score_file_path = 'low_score_comments.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run LDA analysis separately\n",
    "high_score_lda_model, high_score_corpus, high_score_dictionary = run_lda_analysis(high_score_file_path)\n",
    "low_score_lda_model, low_score_corpus, low_score_dictionary = run_lda_analysis(low_score_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Score Comments Topics:\n",
      "Topic: 0 \n",
      "Words: 0.041*\"flight\" + 0.019*\"msp\" + 0.015*\"love\" + 0.013*\"issues\" + 0.012*\"like\" + 0.012*\"2\" + 0.012*\"delayed\" + 0.012*\"terminal\" + 0.012*\"flights\" + 0.011*\"gate\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.025*\"flight\" + 0.019*\"seats\" + 0.016*\"seat\" + 0.011*\"would\" + 0.009*\"way\" + 0.009*\"one\" + 0.007*\"like\" + 0.007*\"us\" + 0.007*\"bag\" + 0.007*\"free\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.154*\"great\" + 0.140*\"service\" + 0.130*\"good\" + 0.049*\"flight\" + 0.047*\"experience\" + 0.042*\"price\" + 0.027*\"customer\" + 0.026*\"time\" + 0.024*\"prices\" + 0.021*\"excellent\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.110*\"time\" + 0.107*\"flight\" + 0.101*\"friendly\" + 0.088*\"staff\" + 0.037*\"flights\" + 0.036*\"crew\" + 0.035*\"nice\" + 0.030*\"attendants\" + 0.027*\"direct\" + 0.026*\"helpful\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.058*\"price\" + 0.058*\"everything\" + 0.050*\"time\" + 0.048*\"easy\" + 0.045*\"went\" + 0.035*\"flight\" + 0.029*\"well\" + 0.028*\"smooth\" + 0.019*\"boarding\" + 0.017*\"smoothly\"\n",
      "\n",
      "Low Score Comments Topics:\n",
      "Topic: 0 \n",
      "Words: 0.092*\"flight\" + 0.025*\"attendants\" + 0.018*\"rude\" + 0.016*\"attendant\" + 0.016*\"staff\" + 0.012*\"delays\" + 0.009*\"crew\" + 0.008*\"experience\" + 0.008*\"friendly\" + 0.008*\"dirty\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.045*\"seat\" + 0.045*\"seats\" + 0.016*\"pay\" + 0.015*\"bag\" + 0.015*\"uncomfortable\" + 0.013*\"like\" + 0.012*\"extra\" + 0.012*\"paid\" + 0.012*\"row\" + 0.010*\"small\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.013*\"flight\" + 0.013*\"us\" + 0.012*\"would\" + 0.012*\"check\" + 0.011*\"get\" + 0.010*\"one\" + 0.010*\"told\" + 0.009*\"bag\" + 0.008*\"gate\" + 0.008*\"said\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.065*\"flight\" + 0.034*\"delayed\" + 0.025*\"hour\" + 0.023*\"hours\" + 0.017*\"gate\" + 0.017*\"time\" + 0.016*\"delay\" + 0.015*\"late\" + 0.014*\"minutes\" + 0.011*\"flights\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.043*\"service\" + 0.020*\"customer\" + 0.019*\"wifi\" + 0.018*\"fees\" + 0.015*\"snacks\" + 0.014*\"leg\" + 0.013*\"poor\" + 0.013*\"entertainment\" + 0.012*\"price\" + 0.012*\"seating\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print topics for high score comments\n",
    "print(\"High Score Comments Topics:\")\n",
    "for idx, topic in high_score_lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")\n",
    "\n",
    "# Print topics for low score comments\n",
    "print(\"Low Score Comments Topics:\")\n",
    "for idx, topic in low_score_lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CSV file\n",
    "manipulated_data_combine = pd.read_csv('manipulated_data_combine.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Departure Date' is a datetime type\n",
    "manipulated_data_combine['Departure Date'] = pd.to_datetime(manipulated_data_combine['Departure Date'])\n",
    "\n",
    "# Function to determine the season based on the month\n",
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 1  # Winter\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 2  # Spring\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 3  # Summer\n",
    "    else:\n",
    "        return 4  # Autumn\n",
    "\n",
    "# Apply the function to create the 'season' column\n",
    "manipulated_data_combine['Season'] = manipulated_data_combine['Departure Date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  score   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     1397.\n",
      "Date:                Tue, 19 Mar 2024   Prob (F-statistic):               0.00\n",
      "Time:                        12:15:04   Log-Likelihood:            -1.1301e+05\n",
      "No. Observations:               68358   AIC:                         2.260e+05\n",
      "Df Residuals:                   68355   BIC:                         2.261e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           4.1163      0.019    220.618      0.000       4.080       4.153\n",
      "Time in Air     0.0006      0.000      5.983      0.000       0.000       0.001\n",
      "Delayed        -0.5197      0.010    -52.359      0.000      -0.539      -0.500\n",
      "==============================================================================\n",
      "Omnibus:                     9889.984   Durbin-Watson:                   1.655\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14867.661\n",
      "Skew:                          -1.135   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.258   Cond. No.                         681.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# List of columns to include in the regression model\n",
    "model_columns = ['Time in Air', 'Delayed', 'score']\n",
    "\n",
    "# Check if there are other numeric columns that should be included in the model\n",
    "# Add them to model_columns as needed\n",
    "\n",
    "# Create X and y for the new model\n",
    "X = manipulated_data_combine[model_columns].drop('score', axis=1)\n",
    "y = manipulated_data_combine['score']\n",
    "\n",
    "# Convert all columns in X to float64 to ensure numeric consistency\n",
    "X = X.astype(float)\n",
    "\n",
    "# Add a constant to X and fit the OLS model\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  score   R-squared:                       0.082\n",
      "Model:                            OLS   Adj. R-squared:                  0.082\n",
      "Method:                 Least Squares   F-statistic:                     1218.\n",
      "Date:                Tue, 19 Mar 2024   Prob (F-statistic):               0.00\n",
      "Time:                        14:23:10   Log-Likelihood:            -1.1147e+05\n",
      "No. Observations:               68358   AIC:                         2.229e+05\n",
      "Df Residuals:                   68352   BIC:                         2.230e+05\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    4.1262      0.023    178.700      0.000       4.081       4.171\n",
      "Time in Air              0.0007      0.000      6.487      0.000       0.000       0.001\n",
      "Delayed                 -0.3181      0.011    -30.139      0.000      -0.339      -0.297\n",
      "Departure Delay Time     0.0046      0.000     14.824      0.000       0.004       0.005\n",
      "Arrival Delay Time      -0.0078      0.000    -26.122      0.000      -0.008      -0.007\n",
      "Season                  -0.0185      0.004     -4.436      0.000      -0.027      -0.010\n",
      "==============================================================================\n",
      "Omnibus:                    10069.030   Durbin-Watson:                   1.717\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15122.661\n",
      "Skew:                          -1.129   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.462   Cond. No.                         876.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Assuming you want to include these in your regression model along with the previous variables\n",
    "model_columns = ['Time in Air', 'Delayed', 'Departure Delay Time', 'Arrival Delay Time', 'score', 'Season']\n",
    "\n",
    "# Create X and y for the new model\n",
    "X = manipulated_data_combine[model_columns].drop('score', axis=1)\n",
    "y = manipulated_data_combine['score']\n",
    "\n",
    "# Convert all columns in X to float64 to ensure numeric consistency\n",
    "X = X.astype(float)\n",
    "\n",
    "# Add a constant to X and fit the OLS model\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
