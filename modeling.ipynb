{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in CSV file\n",
    "survey_response = pd.read_csv('survey_response.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of words to ignore\n",
    "unwanted_words = {'plane', 'sun', 'country', 'fly', 'flying'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to preprocess the text\n",
    "\n",
    "def process_text(text):\n",
    "    # Typecast to string if text is not already a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    # Load English stop words from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Convert text to lowercase for case folding\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation using a regular expression\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text by splitting on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "     # Remove stop words and unwanted words from tokens\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words and token not in unwanted_words]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA Modeling\n",
    "\n",
    "# Define the function to run LDA analysis\n",
    "\n",
    "def run_lda_analysis(file_path, num_topics=5, passes=20, random_state=42):\n",
    "    # Read and preprocess text\n",
    "    texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for comment in file:\n",
    "            processed_comment = process_text(comment)\n",
    "            if processed_comment:  # Check if comment is not empty after preprocessing\n",
    "                texts.append(processed_comment)\n",
    "    \n",
    "    # Create a dictionary and corpus\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # LDA model\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "\n",
    "    return lda_model, corpus, dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File paths\n",
    "high_score_file_path = 'high_score_comments.txt'\n",
    "low_score_file_path = 'low_score_comments.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run LDA analysis separately\n",
    "high_score_lda_model, high_score_corpus, high_score_dictionary = run_lda_analysis(high_score_file_path)\n",
    "low_score_lda_model, low_score_corpus, low_score_dictionary = run_lda_analysis(low_score_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print topics for high score comments\n",
    "print(\"High Score Comments Topics:\")\n",
    "for idx, topic in high_score_lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print topics for low score comments\n",
    "print(\"Low Score Comments Topics:\")\n",
    "for idx, topic in low_score_lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression Modeling\n",
    "\n",
    "# read in the csv file that contains the manipulated data (manipulated to fix date issues related to flight departure date and the date a customer began traveling)\n",
    "manipulated_data_combine = pd.read_csv('manipulated_data_combine.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Departure Date' is a datetime type\n",
    "manipulated_data_combine['Departure Date'] = pd.to_datetime(manipulated_data_combine['Departure Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to determine the season based on the month\n",
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 1  # Winter\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 2  # Spring\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 3  # Summer\n",
    "    else:\n",
    "        return 4  # Autumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the function to create the 'season' column\n",
    "manipulated_data_combine['Season'] = manipulated_data_combine['Departure Date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Model 1: Using 'Time in Air' and 'Delayed' as predictors\n",
    "\n",
    "# List of columns to include in the regression model\n",
    "model_columns = ['Time in Air', 'Delayed', 'score']\n",
    "\n",
    "# Check if there are other numeric columns that should be included in the model\n",
    "# Add them to model_columns as needed\n",
    "\n",
    "# Create X and y for the new model\n",
    "X = manipulated_data_combine[model_columns].drop('score', axis=1)\n",
    "y = manipulated_data_combine['score']\n",
    "\n",
    "# Convert all columns in X to float64 to ensure numeric consistency\n",
    "X = X.astype(float)\n",
    "\n",
    "# Add a constant to X and fit the OLS model\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Model 2: Including 'Departure Delay Time' and 'Arrival Delay Time' as predictors along with the prior predictors\n",
    "\n",
    "# Including more independent variables in the regression model\n",
    "model_columns = ['Time in Air', 'Delayed', 'Departure Delay Time', 'Arrival Delay Time', 'score', 'Season']\n",
    "\n",
    "# Create X and y for the new model\n",
    "X = manipulated_data_combine[model_columns].drop('score', axis=1)\n",
    "y = manipulated_data_combine['score']\n",
    "\n",
    "# Convert all columns in X to float64 to ensure numeric consistency\n",
    "X = X.astype(float)\n",
    "\n",
    "# Add a constant to X and fit the OLS model\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
