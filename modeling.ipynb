{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in CSV file\n",
    "survey_response = pd.read_csv('survey_response.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of words to ignore\n",
    "unwanted_words = {'plane', 'sun', 'country', 'fly', 'flying'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    # Typecast to string if text is not already a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    # Load English stop words from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Convert text to lowercase for case folding\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation using a regular expression\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text by splitting on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "     # Remove stop words and unwanted words from tokens\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words and token not in unwanted_words]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_lda_analysis(file_path, num_topics=5, passes=20):\n",
    "    # Read and preprocess text\n",
    "    texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for comment in file:\n",
    "            processed_comment = process_text(comment)\n",
    "            if processed_comment:  # Check if comment is not empty after preprocessing\n",
    "                texts.append(processed_comment)\n",
    "    \n",
    "    # Create a dictionary and corpus\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # LDA model\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "\n",
    "    return lda_model, corpus, dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File paths\n",
    "high_score_file_path = 'high_score_comments.txt'\n",
    "low_score_file_path = 'low_score_comments.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run LDA analysis separately\n",
    "high_score_lda_model, high_score_corpus, high_score_dictionary = run_lda_analysis(high_score_file_path)\n",
    "low_score_lda_model, low_score_corpus, low_score_dictionary = run_lda_analysis(low_score_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Score Comments Topics:\n",
      "Topic: 0 \n",
      "Words: 0.021*\"seats\" + 0.019*\"like\" + 0.018*\"seat\" + 0.015*\"would\" + 0.011*\"terminal\" + 0.009*\"2\" + 0.008*\"bag\" + 0.008*\"free\" + 0.008*\"msp\" + 0.008*\"room\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.069*\"flight\" + 0.013*\"us\" + 0.013*\"gate\" + 0.013*\"early\" + 0.012*\"time\" + 0.011*\"delayed\" + 0.009*\"delay\" + 0.009*\"get\" + 0.009*\"got\" + 0.009*\"arrived\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.118*\"flight\" + 0.112*\"time\" + 0.089*\"friendly\" + 0.078*\"staff\" + 0.034*\"great\" + 0.031*\"easy\" + 0.031*\"nice\" + 0.029*\"smooth\" + 0.029*\"crew\" + 0.028*\"attendants\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.135*\"service\" + 0.125*\"good\" + 0.104*\"great\" + 0.046*\"experience\" + 0.038*\"always\" + 0.034*\"time\" + 0.026*\"customer\" + 0.023*\"prices\" + 0.020*\"flights\" + 0.019*\"value\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.128*\"price\" + 0.069*\"everything\" + 0.059*\"flight\" + 0.054*\"went\" + 0.045*\"direct\" + 0.029*\"flights\" + 0.025*\"well\" + 0.025*\"reasonable\" + 0.022*\"cost\" + 0.020*\"smoothly\"\n",
      "\n",
      "Low Score Comments Topics:\n",
      "Topic: 0 \n",
      "Words: 0.097*\"flight\" + 0.050*\"delayed\" + 0.028*\"hours\" + 0.023*\"delay\" + 0.018*\"hour\" + 0.017*\"time\" + 0.017*\"flights\" + 0.014*\"late\" + 0.012*\"communication\" + 0.011*\"2\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.032*\"seat\" + 0.031*\"seats\" + 0.019*\"flight\" + 0.011*\"uncomfortable\" + 0.010*\"pay\" + 0.010*\"extra\" + 0.010*\"like\" + 0.009*\"paid\" + 0.009*\"row\" + 0.008*\"bag\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.032*\"gate\" + 0.020*\"minutes\" + 0.019*\"hour\" + 0.017*\"get\" + 0.016*\"boarding\" + 0.015*\"luggage\" + 0.014*\"time\" + 0.014*\"check\" + 0.014*\"flight\" + 0.014*\"wait\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.020*\"flight\" + 0.015*\"us\" + 0.014*\"would\" + 0.011*\"told\" + 0.010*\"get\" + 0.010*\"one\" + 0.010*\"back\" + 0.009*\"said\" + 0.009*\"could\" + 0.008*\"never\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.052*\"flight\" + 0.048*\"service\" + 0.027*\"rude\" + 0.024*\"attendants\" + 0.022*\"staff\" + 0.021*\"customer\" + 0.016*\"poor\" + 0.014*\"delays\" + 0.014*\"experience\" + 0.013*\"dirty\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print topics for high score comments\n",
    "print(\"High Score Comments Topics:\")\n",
    "for idx, topic in high_score_lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")\n",
    "\n",
    "# Print topics for low score comments\n",
    "print(\"Low Score Comments Topics:\")\n",
    "for idx, topic in low_score_lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
