{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_response = pd.read_csv('survey_response.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start City Counts:\n",
      "ServiceStartCity\n",
      "MSP    18812\n",
      "RSW     5331\n",
      "LAS     4847\n",
      "PHX     4703\n",
      "MCO     3979\n",
      "       ...  \n",
      "SLC        1\n",
      "CHS        1\n",
      "BDL        1\n",
      "BTV        1\n",
      "GPT        1\n",
      "Name: count, Length: 97, dtype: int64\n",
      "\n",
      "End City Counts:\n",
      "ServiceEndCity\n",
      "MSP    44844\n",
      "RSW     2570\n",
      "PHX     2023\n",
      "MCO     1472\n",
      "LAX     1256\n",
      "       ...  \n",
      "CHS        1\n",
      "BDL        1\n",
      "SLC        1\n",
      "SDF        1\n",
      "BKG        1\n",
      "Name: count, Length: 88, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count of unique values in 'ServiceStartCity'\n",
    "start_city_counts = survey_response['ServiceStartCity'].value_counts()\n",
    "\n",
    "# Count of unique values in 'ServiceEndCity'\n",
    "end_city_counts = survey_response['ServiceEndCity'].value_counts()\n",
    "\n",
    "# If you want to print or view the counts\n",
    "print(\"Start City Counts:\")\n",
    "print(start_city_counts)\n",
    "print(\"\\nEnd City Counts:\")\n",
    "print(end_city_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "1     6101\n",
      "2     4314\n",
      "3     7364\n",
      "4    15578\n",
      "5    35353\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Counting each value in the 'score' column\n",
    "score_counts = survey_response['score'].value_counts()\n",
    "\n",
    "# Sorting the counts by the score values if needed (e.g., for numeric scores)\n",
    "score_counts_sorted = score_counts.sort_index()\n",
    "\n",
    "print(score_counts_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ServiceStartDate' to datetime format\n",
    "survey_response['ServiceStartDate'] = pd.to_datetime(survey_response['ServiceStartDate'], format='%m/%d/%Y')\n",
    "\n",
    "# Define a function to determine the season based on the month\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'spring'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'summer'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'fall'\n",
    "    else: # months 12, 1, 2\n",
    "        return 'winter'\n",
    "\n",
    "# Apply the function to each row to create the 'season' column\n",
    "survey_response['season'] = survey_response['ServiceStartDate'].dt.month.apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the comment column to string data type from object data type\n",
    "survey_response['comment'] = survey_response['comment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City Pair\n",
      "LAS-MSP    620\n",
      "MCO-MSP    594\n",
      "PHX-MSP    566\n",
      "RSW-MSP    523\n",
      "LAX-MSP    336\n",
      "          ... \n",
      "MSP-CHS      0\n",
      "CMH-MSP      0\n",
      "MSP-PHL      0\n",
      "MSP-BZN      0\n",
      "JAC-MSP      0\n",
      "Length: 239, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Grouping by 'City Pair' and then counting each 'score' value\n",
    "score_counts_per_city_pair = survey_response.groupby(['City Pair', 'score']).size().unstack(fill_value=0)\n",
    "\n",
    "# scores <= 2 as low:\n",
    "low_scores_per_city_pair = score_counts_per_city_pair.loc[:, score_counts_per_city_pair.columns <= 2]\n",
    "\n",
    "# To find city pairs with the most low scores (summing across all low scores)\n",
    "most_low_scores = low_scores_per_city_pair.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "print(most_low_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City Pair\n",
      "LAS-MSP    3285\n",
      "RSW-MSP    3099\n",
      "PHX-MSP    2939\n",
      "MCO-MSP    2917\n",
      "MSP-RSW    1609\n",
      "           ... \n",
      "MAF-DFW       0\n",
      "SAT-MSP       0\n",
      "MSP-AUS       0\n",
      "BTV-MSP       0\n",
      "IAH-DFW       0\n",
      "Length: 239, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Focus on scores of 4 and 5\n",
    "high_scores_per_city_pair = score_counts_per_city_pair.loc[:, score_counts_per_city_pair.columns.isin([4, 5])]\n",
    "\n",
    "# To find city pairs with the most high scores (summing across scores of 4 and 5)\n",
    "most_high_scores = high_scores_per_city_pair.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "print(most_high_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all comments into a single string\n",
    "# You can separate each comment with a newline character for better readability\n",
    "all_comments = '\\n'.join(survey_response['comment'].astype(str))\n",
    "\n",
    "# Write the combined string to a text file\n",
    "with open('C:/Users/james/OneDrive/Documents/Capstone/Capstone/all_comments.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Typecast to string if text is not already a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    # Load English stop words from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Convert text to lowercase for case folding\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation using a regular expression\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text by splitting on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stop words from tokens\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_all_comments= process_text(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Function that gives summary stats dictionary for a given text\n",
    "def get_patterns(text)  :\n",
    "    \"\"\"\n",
    "        This function takes text as an input and returns a dictionary of statistics,\n",
    "        after cleaning the text. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Calculate your statistics here\n",
    "    total_tokens = len(text)\n",
    "    unique_tokens = set(text)\n",
    "    len_unique_tokens = len(unique_tokens)\n",
    "    avg_token_len = sum([len(token) for token in text]) / total_tokens if total_tokens > 0 else 0\n",
    "    lex_diversity = len_unique_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    top_10 = Counter(text).most_common(20)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Now we'll fill out the dictionary. \n",
    "    results = {'tokens':total_tokens,\n",
    "               'unique_tokens':len_unique_tokens,\n",
    "               'avg_token_length':avg_token_len,\n",
    "               'lexical_diversity':lex_diversity,\n",
    "               'top_10':top_10}\n",
    "\n",
    "    return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': 662581,\n",
       " 'unique_tokens': 19420,\n",
       " 'avg_token_length': 5.806447815436905,\n",
       " 'lexical_diversity': 0.029309624030873206,\n",
       " 'top_10': [('flight', 29069),\n",
       "  ('time', 14267),\n",
       "  ('service', 9867),\n",
       "  ('great', 9003),\n",
       "  ('good', 8128),\n",
       "  ('staff', 7347),\n",
       "  ('friendly', 7271),\n",
       "  ('flights', 7049),\n",
       "  ('plane', 6230),\n",
       "  ('sun', 6027),\n",
       "  ('country', 5733),\n",
       "  ('price', 5456),\n",
       "  ('delayed', 4364),\n",
       "  ('experience', 3824),\n",
       "  ('seats', 3804),\n",
       "  ('get', 3725),\n",
       "  ('seat', 3561),\n",
       "  ('attendants', 3524),\n",
       "  ('gate', 3410),\n",
       "  ('hour', 3244)]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_patterns(processed_all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for scores 4 and 5, and concatenate the comments\n",
    "high_score_comments = '\\n'.join(survey_response[survey_response['score'].isin([4, 5])]['comment'].astype(str))\n",
    "\n",
    "# Write the high score comments to a text file\n",
    "with open('C:/Users/james/OneDrive/Documents/Capstone/Capstone/high_score_comments.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(high_score_comments)\n",
    "\n",
    "# Filter the DataFrame for scores 1, 2, and 3 and concatenate the comments\n",
    "low_score_comments = '\\n'.join(survey_response[survey_response['score'].isin([1, 2, 3])]['comment'].astype(str))\n",
    "\n",
    "# Write the low score comments to a text file\n",
    "with open('C:/Users/james/OneDrive/Documents/Capstone/Capstone/low_score_comments.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(low_score_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_high_score_comments = process_text(high_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_low_score_comments = process_text(low_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': 333201,\n",
       " 'unique_tokens': 11989,\n",
       " 'avg_token_length': 5.940327309942047,\n",
       " 'lexical_diversity': 0.03598128456997428,\n",
       " 'top_10': [('flight', 16716),\n",
       "  ('time', 11533),\n",
       "  ('great', 8518),\n",
       "  ('service', 8027),\n",
       "  ('good', 7398),\n",
       "  ('friendly', 6917),\n",
       "  ('staff', 6261),\n",
       "  ('flights', 5322),\n",
       "  ('price', 4968),\n",
       "  ('sun', 3347),\n",
       "  ('country', 3175),\n",
       "  ('everything', 2862),\n",
       "  ('experience', 2740),\n",
       "  ('nice', 2646),\n",
       "  ('easy', 2469),\n",
       "  ('plane', 2416),\n",
       "  ('attendants', 2408),\n",
       "  ('crew', 2361),\n",
       "  ('went', 2217),\n",
       "  ('always', 2179)]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_patterns(processed_high_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': 329380,\n",
       " 'unique_tokens': 14298,\n",
       " 'avg_token_length': 5.6710152407553585,\n",
       " 'lexical_diversity': 0.0434088287084826,\n",
       " 'top_10': [('flight', 12353),\n",
       "  ('plane', 3814),\n",
       "  ('delayed', 3503),\n",
       "  ('time', 2734),\n",
       "  ('sun', 2680),\n",
       "  ('hour', 2605),\n",
       "  ('get', 2575),\n",
       "  ('country', 2558),\n",
       "  ('hours', 2493),\n",
       "  ('gate', 2469),\n",
       "  ('seat', 2242),\n",
       "  ('seats', 2167),\n",
       "  ('us', 2049),\n",
       "  ('one', 1954),\n",
       "  ('service', 1840),\n",
       "  ('would', 1774),\n",
       "  ('luggage', 1752),\n",
       "  ('flights', 1727),\n",
       "  ('delay', 1635),\n",
       "  ('back', 1629)]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_patterns(processed_low_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function to compare two corpora\n",
    "def group_compare(corpus_1, corpus_2, num_words=10, ratio_cutoff=5):\n",
    "    sum_stats_corp_1 = get_patterns(corpus_1)\n",
    "    sum_stats_corp_2 = get_patterns(corpus_2)\n",
    "\n",
    "    # Extract word frequencies for both corpora\n",
    "    freq_1 = Counter(corpus_1)\n",
    "    freq_2 = Counter(corpus_2)\n",
    "\n",
    "    # Calculate ratios for words that appear at least ratio_cutoff times in both corpora\n",
    "    ratios_one_vs_two = {}\n",
    "    ratios_two_vs_one = {}\n",
    "\n",
    "    for word, count in freq_1.items():\n",
    "        if word in freq_2 and count >= ratio_cutoff and freq_2[word] >= ratio_cutoff:\n",
    "            p_1 = count / sum_stats_corp_1[\"tokens\"]\n",
    "            p_2 = freq_2[word] / sum_stats_corp_2[\"tokens\"]\n",
    "            ratios_one_vs_two[word] = p_1 / p_2\n",
    "            ratios_two_vs_one[word] = p_2 / p_1\n",
    "\n",
    "    # Sort and get top num_words for both ratios\n",
    "    top_ratios_one_vs_two = sorted(ratios_one_vs_two.items(), key=lambda x: x[1], reverse=True)[:num_words]\n",
    "    top_ratios_two_vs_one = sorted(ratios_two_vs_one.items(), key=lambda x: x[1], reverse=True)[:num_words]\n",
    "\n",
    "    results = {\n",
    "        \"one\": sum_stats_corp_1,\n",
    "        \"two\": sum_stats_corp_2,\n",
    "        \"one_vs_two\": dict(top_ratios_one_vs_two),\n",
    "        \"two_vs_one\": dict(top_ratios_two_vs_one)\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': {'tokens': 333201,\n",
       "  'unique_tokens': 11989,\n",
       "  'avg_token_length': 5.940327309942047,\n",
       "  'lexical_diversity': 0.03598128456997428,\n",
       "  'top_10': [('flight', 16716),\n",
       "   ('time', 11533),\n",
       "   ('great', 8518),\n",
       "   ('service', 8027),\n",
       "   ('good', 7398),\n",
       "   ('friendly', 6917),\n",
       "   ('staff', 6261),\n",
       "   ('flights', 5322),\n",
       "   ('price', 4968),\n",
       "   ('sun', 3347),\n",
       "   ('country', 3175),\n",
       "   ('everything', 2862),\n",
       "   ('experience', 2740),\n",
       "   ('nice', 2646),\n",
       "   ('easy', 2469),\n",
       "   ('plane', 2416),\n",
       "   ('attendants', 2408),\n",
       "   ('crew', 2361),\n",
       "   ('went', 2217),\n",
       "   ('always', 2179)]},\n",
       " 'two': {'tokens': 329380,\n",
       "  'unique_tokens': 14298,\n",
       "  'avg_token_length': 5.6710152407553585,\n",
       "  'lexical_diversity': 0.0434088287084826,\n",
       "  'top_10': [('flight', 12353),\n",
       "   ('plane', 3814),\n",
       "   ('delayed', 3503),\n",
       "   ('time', 2734),\n",
       "   ('sun', 2680),\n",
       "   ('hour', 2605),\n",
       "   ('get', 2575),\n",
       "   ('country', 2558),\n",
       "   ('hours', 2493),\n",
       "   ('gate', 2469),\n",
       "   ('seat', 2242),\n",
       "   ('seats', 2167),\n",
       "   ('us', 2049),\n",
       "   ('one', 1954),\n",
       "   ('service', 1840),\n",
       "   ('would', 1774),\n",
       "   ('luggage', 1752),\n",
       "   ('flights', 1727),\n",
       "   ('delay', 1635),\n",
       "   ('back', 1629)]},\n",
       " 'one_vs_two': {'smoothly': 67.71447264564031,\n",
       "  'easy': 55.47015028602719,\n",
       "  'ease': 54.08684676387955,\n",
       "  'smooth': 35.972528212344365,\n",
       "  'reasonably': 34.40092916888005,\n",
       "  'convenient': 33.90084804843993,\n",
       "  'affordable': 29.853679910924637,\n",
       "  'courteous': 29.11228057538843,\n",
       "  'efficient': 28.4203078622213,\n",
       "  'excellent': 28.148461439191358},\n",
       " 'two_vs_one': {'apology': 14.162408160786933,\n",
       "  'poor': 13.99380806363471,\n",
       "  'worst': 12.861778839898339,\n",
       "  'send': 12.746167344708239,\n",
       "  '200': 12.139206994960228,\n",
       "  'unacceptable': 11.858206833039853,\n",
       "  'poorly': 11.464806606351328,\n",
       "  'refused': 11.127606412046875,\n",
       "  'refund': 11.064381375614792,\n",
       "  'supervisor': 10.959006314894651}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_compare(processed_high_score_comments, processed_low_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
