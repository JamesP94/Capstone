{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_response = pd.read_csv('survey_response.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start City Counts:\n",
      "ServiceStartCity\n",
      "MSP    18812\n",
      "RSW     5331\n",
      "LAS     4847\n",
      "PHX     4703\n",
      "MCO     3979\n",
      "       ...  \n",
      "SLC        1\n",
      "CHS        1\n",
      "BDL        1\n",
      "BTV        1\n",
      "GPT        1\n",
      "Name: count, Length: 97, dtype: int64\n",
      "\n",
      "End City Counts:\n",
      "ServiceEndCity\n",
      "MSP    44844\n",
      "RSW     2570\n",
      "PHX     2023\n",
      "MCO     1472\n",
      "LAX     1256\n",
      "       ...  \n",
      "CHS        1\n",
      "BDL        1\n",
      "SLC        1\n",
      "SDF        1\n",
      "BKG        1\n",
      "Name: count, Length: 88, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count of unique values in 'ServiceStartCity'\n",
    "start_city_counts = survey_response['ServiceStartCity'].value_counts()\n",
    "\n",
    "# Count of unique values in 'ServiceEndCity'\n",
    "end_city_counts = survey_response['ServiceEndCity'].value_counts()\n",
    "\n",
    "# If you want to print or view the counts\n",
    "print(\"Start City Counts:\")\n",
    "print(start_city_counts)\n",
    "print(\"\\nEnd City Counts:\")\n",
    "print(end_city_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ServiceStartDate  season\n",
      "0       2023-01-01  winter\n",
      "1       2023-01-01  winter\n",
      "2       2023-01-01  winter\n",
      "3       2023-01-01  winter\n",
      "4       2023-01-01  winter\n",
      "5       2023-01-01  winter\n",
      "6       2023-01-01  winter\n",
      "7       2023-01-01  winter\n",
      "8       2023-01-01  winter\n",
      "9       2023-01-01  winter\n"
     ]
    }
   ],
   "source": [
    "# Convert 'ServiceStartDate' to datetime format\n",
    "survey_response['ServiceStartDate'] = pd.to_datetime(survey_response['ServiceStartDate'], format='%m/%d/%Y')\n",
    "\n",
    "# Define a function to determine the season based on the month\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'spring'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'summer'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'fall'\n",
    "    else: # months 12, 1, 2\n",
    "        return 'winter'\n",
    "\n",
    "# Apply the function to each row to create the 'season' column\n",
    "survey_response['season'] = survey_response['ServiceStartDate'].dt.month.apply(get_season)\n",
    "\n",
    "# Check the result\n",
    "print(survey_response[['ServiceStartDate', 'season']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the comment column to string data type from object data type\n",
    "survey_response['comment'] = survey_response['comment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all comments into a single string\n",
    "# You can separate each comment with a newline character for better readability\n",
    "all_comments = '\\n'.join(survey_response['comment'].astype(str))\n",
    "\n",
    "# Write the combined string to a text file\n",
    "with open('C:/Users/james/OneDrive/Documents/Capstone/Capstone/all_comments.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Load English stop words from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Convert text to lowercase for case folding\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation using a regular expression\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text by splitting on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stop words from tokens\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_all_comments= process_text(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Function that gives summary stats dictionary for a given text\n",
    "def get_patterns(text)  :\n",
    "    \"\"\"\n",
    "        This function takes text as an input and returns a dictionary of statistics,\n",
    "        after cleaning the text. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Calculate your statistics here\n",
    "    total_tokens = len(text)\n",
    "    unique_tokens = set(text)\n",
    "    len_unique_tokens = len(unique_tokens)\n",
    "    avg_token_len = sum([len(token) for token in text]) / total_tokens\n",
    "    lex_diversity = len_unique_tokens / total_tokens\n",
    "    top_10 = Counter(text).most_common(20)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Now we'll fill out the dictionary. \n",
    "    results = {'tokens':total_tokens,\n",
    "               'unique_tokens':len_unique_tokens,\n",
    "               'avg_token_length':avg_token_len,\n",
    "               'lexical_diversity':lex_diversity,\n",
    "               'top_10':top_10}\n",
    "\n",
    "    return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': 662581,\n",
       " 'unique_tokens': 19420,\n",
       " 'avg_token_length': 5.806447815436905,\n",
       " 'lexical_diversity': 0.029309624030873206,\n",
       " 'top_10': [('flight', 29069),\n",
       "  ('time', 14267),\n",
       "  ('service', 9867),\n",
       "  ('great', 9003),\n",
       "  ('good', 8128),\n",
       "  ('staff', 7347),\n",
       "  ('friendly', 7271),\n",
       "  ('flights', 7049),\n",
       "  ('plane', 6230),\n",
       "  ('sun', 6027),\n",
       "  ('country', 5733),\n",
       "  ('price', 5456),\n",
       "  ('delayed', 4364),\n",
       "  ('experience', 3824),\n",
       "  ('seats', 3804),\n",
       "  ('get', 3725),\n",
       "  ('seat', 3561),\n",
       "  ('attendants', 3524),\n",
       "  ('gate', 3410),\n",
       "  ('hour', 3244)]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_patterns(processed_all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for scores 4 and 5, and concatenate the comments\n",
    "high_score_comments = '\\n'.join(survey_response[survey_response['score'].isin([4, 5])]['comment'].astype(str))\n",
    "\n",
    "# Write the high score comments to a text file\n",
    "with open('C:/Users/james/OneDrive/Documents/Capstone/Capstone/high_score_comments.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(high_score_comments)\n",
    "\n",
    "# Filter the DataFrame for scores 1 and 2, and concatenate the comments\n",
    "low_score_comments = '\\n'.join(survey_response[survey_response['score'].isin([1, 2])]['comment'].astype(str))\n",
    "\n",
    "# Write the low score comments to a text file\n",
    "with open('C:/Users/james/OneDrive/Documents/Capstone/Capstone/low_score_comments.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(low_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_high_score_comments = process_text(high_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_low_score_comments = process_text(low_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Check the type of 'processed_high_score_comments'\n",
    "data_type = type(processed_high_score_comments)\n",
    "\n",
    "print(data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': 333201,\n",
       " 'unique_tokens': 11989,\n",
       " 'avg_token_length': 5.940327309942047,\n",
       " 'lexical_diversity': 0.03598128456997428,\n",
       " 'top_10': [('flight', 16716),\n",
       "  ('time', 11533),\n",
       "  ('great', 8518),\n",
       "  ('service', 8027),\n",
       "  ('good', 7398),\n",
       "  ('friendly', 6917),\n",
       "  ('staff', 6261),\n",
       "  ('flights', 5322),\n",
       "  ('price', 4968),\n",
       "  ('sun', 3347),\n",
       "  ('country', 3175),\n",
       "  ('everything', 2862),\n",
       "  ('experience', 2740),\n",
       "  ('nice', 2646),\n",
       "  ('easy', 2469),\n",
       "  ('plane', 2416),\n",
       "  ('attendants', 2408),\n",
       "  ('crew', 2361),\n",
       "  ('went', 2217),\n",
       "  ('always', 2179)]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_patterns(processed_high_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': 212978,\n",
       " 'unique_tokens': 11518,\n",
       " 'avg_token_length': 5.668928246109926,\n",
       " 'lexical_diversity': 0.05408070317121956,\n",
       " 'top_10': [('flight', 7976),\n",
       "  ('plane', 2497),\n",
       "  ('delayed', 2442),\n",
       "  ('hours', 1881),\n",
       "  ('sun', 1848),\n",
       "  ('hour', 1831),\n",
       "  ('country', 1762),\n",
       "  ('get', 1712),\n",
       "  ('time', 1693),\n",
       "  ('gate', 1624),\n",
       "  ('us', 1449),\n",
       "  ('service', 1276),\n",
       "  ('one', 1276),\n",
       "  ('seat', 1252),\n",
       "  ('luggage', 1147),\n",
       "  ('delay', 1145),\n",
       "  ('would', 1131),\n",
       "  ('seats', 1102),\n",
       "  ('bag', 1076),\n",
       "  ('airport', 1051)]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_patterns(processed_low_score_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function to compare two corpora\n",
    "def group_compare(corpus_1, corpus_2, num_words=10, ratio_cutoff=5):\n",
    "    sum_stats_corp_1 = get_patterns(corpus_1)\n",
    "    sum_stats_corp_2 = get_patterns(corpus_2)\n",
    "\n",
    "    # Extract word frequencies for both corpora\n",
    "    freq_1 = Counter(corpus_1)\n",
    "    freq_2 = Counter(corpus_2)\n",
    "\n",
    "    # Calculate ratios for words that appear at least ratio_cutoff times in both corpora\n",
    "    ratios_one_vs_two = {}\n",
    "    ratios_two_vs_one = {}\n",
    "\n",
    "    for word, count in freq_1.items():\n",
    "        if word in freq_2 and count >= ratio_cutoff and freq_2[word] >= ratio_cutoff:\n",
    "            p_1 = count / sum_stats_corp_1[\"tokens\"]\n",
    "            p_2 = freq_2[word] / sum_stats_corp_2[\"tokens\"]\n",
    "            ratios_one_vs_two[word] = p_1 / p_2\n",
    "            ratios_two_vs_one[word] = p_2 / p_1\n",
    "\n",
    "    # Sort and get top num_words for both ratios\n",
    "    top_ratios_one_vs_two = sorted(ratios_one_vs_two.items(), key=lambda x: x[1], reverse=True)[:num_words]\n",
    "    top_ratios_two_vs_one = sorted(ratios_two_vs_one.items(), key=lambda x: x[1], reverse=True)[:num_words]\n",
    "\n",
    "    results = {\n",
    "        \"one\": sum_stats_corp_1,\n",
    "        \"two\": sum_stats_corp_2,\n",
    "        \"one_vs_two\": dict(top_ratios_one_vs_two),\n",
    "        \"two_vs_one\": dict(top_ratios_two_vs_one)\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': {'tokens': 333201,\n",
       "  'unique_tokens': 11989,\n",
       "  'avg_token_length': 5.940327309942047,\n",
       "  'lexical_diversity': 0.03598128456997428,\n",
       "  'top_10': [('flight', 16716),\n",
       "   ('time', 11533),\n",
       "   ('great', 8518),\n",
       "   ('service', 8027),\n",
       "   ('good', 7398),\n",
       "   ('friendly', 6917),\n",
       "   ('staff', 6261),\n",
       "   ('flights', 5322),\n",
       "   ('price', 4968),\n",
       "   ('sun', 3347),\n",
       "   ('country', 3175),\n",
       "   ('everything', 2862),\n",
       "   ('experience', 2740),\n",
       "   ('nice', 2646),\n",
       "   ('easy', 2469),\n",
       "   ('plane', 2416),\n",
       "   ('attendants', 2408),\n",
       "   ('crew', 2361),\n",
       "   ('went', 2217),\n",
       "   ('always', 2179)]},\n",
       " 'two': {'tokens': 212978,\n",
       "  'unique_tokens': 11518,\n",
       "  'avg_token_length': 5.668928246109926,\n",
       "  'lexical_diversity': 0.05408070317121956,\n",
       "  'top_10': [('flight', 7976),\n",
       "   ('plane', 2497),\n",
       "   ('delayed', 2442),\n",
       "   ('hours', 1881),\n",
       "   ('sun', 1848),\n",
       "   ('hour', 1831),\n",
       "   ('country', 1762),\n",
       "   ('get', 1712),\n",
       "   ('time', 1693),\n",
       "   ('gate', 1624),\n",
       "   ('us', 1449),\n",
       "   ('service', 1276),\n",
       "   ('one', 1276),\n",
       "   ('seat', 1252),\n",
       "   ('luggage', 1147),\n",
       "   ('delay', 1145),\n",
       "   ('would', 1131),\n",
       "   ('seats', 1102),\n",
       "   ('bag', 1076),\n",
       "   ('airport', 1051)]},\n",
       " 'one_vs_two': {'smoothly': 105.0824673395338,\n",
       "  'excellent': 104.00497940539537,\n",
       "  'smooth': 65.3493388303728,\n",
       "  'ease': 61.20222778443043,\n",
       "  'easy': 58.450169383912076,\n",
       "  'convenience': 46.84333137398404,\n",
       "  'affordable': 42.89660061711166,\n",
       "  'courteous': 41.83128768787875,\n",
       "  'efficient': 39.58047267842256,\n",
       "  'perfect': 37.1642024740965},\n",
       " 'two_vs_one': {'worst': 17.358339493146847,\n",
       "  'poor': 15.963546834780013,\n",
       "  'supervisor': 15.905602926123827,\n",
       "  '200': 15.644855337170975,\n",
       "  'unacceptable': 15.123360159265276,\n",
       "  'refused': 14.750863603618347,\n",
       "  'refund': 14.471491186883153,\n",
       "  'apology': 14.080369803453877,\n",
       "  'poorly': 13.819622214501027,\n",
       "  'send': 13.141678483223618}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "group_compare(processed_high_score_comments, processed_low_score_comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
